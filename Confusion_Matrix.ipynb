{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Confusion Matrix.ipynb",
      "provenance": [],
      "mount_file_id": "1krCF63308TQbYfDMf0EDpViasTHy0wXp",
      "authorship_tag": "ABX9TyO9qKdzm03Lrk/a8DloyDXg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajasreekalli/datascience-dojo/blob/main/Confusion_Matrix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2f1TfUZ2qu0g"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import plot_confusion_matrix"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "vQOBNQiertuR",
        "outputId": "a6acbb72-40c6-4ff3-f8aa-9d752d7b7afd"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/cancer.csv')\n",
        "df"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>926424</td>\n",
              "      <td>M</td>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>1.1760</td>\n",
              "      <td>1.2560</td>\n",
              "      <td>7.673</td>\n",
              "      <td>158.70</td>\n",
              "      <td>0.010300</td>\n",
              "      <td>0.02891</td>\n",
              "      <td>0.05198</td>\n",
              "      <td>0.02454</td>\n",
              "      <td>0.01114</td>\n",
              "      <td>0.004239</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>926682</td>\n",
              "      <td>M</td>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>0.7655</td>\n",
              "      <td>2.4630</td>\n",
              "      <td>5.203</td>\n",
              "      <td>99.04</td>\n",
              "      <td>0.005769</td>\n",
              "      <td>0.02423</td>\n",
              "      <td>0.03950</td>\n",
              "      <td>0.01678</td>\n",
              "      <td>0.01898</td>\n",
              "      <td>0.002498</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>926954</td>\n",
              "      <td>M</td>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>0.4564</td>\n",
              "      <td>1.0750</td>\n",
              "      <td>3.425</td>\n",
              "      <td>48.55</td>\n",
              "      <td>0.005903</td>\n",
              "      <td>0.03731</td>\n",
              "      <td>0.04730</td>\n",
              "      <td>0.01557</td>\n",
              "      <td>0.01318</td>\n",
              "      <td>0.003892</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>927241</td>\n",
              "      <td>M</td>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>0.7260</td>\n",
              "      <td>1.5950</td>\n",
              "      <td>5.772</td>\n",
              "      <td>86.22</td>\n",
              "      <td>0.006522</td>\n",
              "      <td>0.06158</td>\n",
              "      <td>0.07117</td>\n",
              "      <td>0.01664</td>\n",
              "      <td>0.02324</td>\n",
              "      <td>0.006185</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>92751</td>\n",
              "      <td>B</td>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>1.4280</td>\n",
              "      <td>2.548</td>\n",
              "      <td>19.15</td>\n",
              "      <td>0.007189</td>\n",
              "      <td>0.00466</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.02676</td>\n",
              "      <td>0.002783</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows Ã— 32 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           id diagnosis  ...  symmetry_worst  fractal_dimension_worst\n",
              "0      842302         M  ...          0.4601                  0.11890\n",
              "1      842517         M  ...          0.2750                  0.08902\n",
              "2    84300903         M  ...          0.3613                  0.08758\n",
              "3    84348301         M  ...          0.6638                  0.17300\n",
              "4    84358402         M  ...          0.2364                  0.07678\n",
              "..        ...       ...  ...             ...                      ...\n",
              "564    926424         M  ...          0.2060                  0.07115\n",
              "565    926682         M  ...          0.2572                  0.06637\n",
              "566    926954         M  ...          0.2218                  0.07820\n",
              "567    927241         M  ...          0.4087                  0.12400\n",
              "568     92751         B  ...          0.2871                  0.07039\n",
              "\n",
              "[569 rows x 32 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2ZukecJsaLp",
        "outputId": "f9b8493a-5d88-4c4f-b794-16627aa7bb6a"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                           int64\n",
              "diagnosis                   object\n",
              "radius_mean                float64\n",
              "texture_mean               float64\n",
              "perimeter_mean             float64\n",
              "area_mean                  float64\n",
              "smoothness_mean            float64\n",
              "compactness_mean           float64\n",
              "concavity_mean             float64\n",
              "concave points_mean        float64\n",
              "symmetry_mean              float64\n",
              "fractal_dimension_mean     float64\n",
              "radius_se                  float64\n",
              "texture_se                 float64\n",
              "perimeter_se               float64\n",
              "area_se                    float64\n",
              "smoothness_se              float64\n",
              "compactness_se             float64\n",
              "concavity_se               float64\n",
              "concave points_se          float64\n",
              "symmetry_se                float64\n",
              "fractal_dimension_se       float64\n",
              "radius_worst               float64\n",
              "texture_worst              float64\n",
              "perimeter_worst            float64\n",
              "area_worst                 float64\n",
              "smoothness_worst           float64\n",
              "compactness_worst          float64\n",
              "concavity_worst            float64\n",
              "concave points_worst       float64\n",
              "symmetry_worst             float64\n",
              "fractal_dimension_worst    float64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ezm1kCxzOwB"
      },
      "source": [
        "# 1) What was the accuracy of the model?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNmbnNVuzS-C"
      },
      "source": [
        "I think random forest trees are having the highest accuracy model to compare the other model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUv9LXZzzmOF"
      },
      "source": [
        "# 2) Which condition (Malignant or Benign) is considered the positive class in this data set?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38WMPnXgzns2"
      },
      "source": [
        "Classification means to predict the class. It is clear. So in diagnosis contain only 2 class i.e M and B. So Malignant or Benign defers the class of the given dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDlm3PE2skE2"
      },
      "source": [
        "df['diagnosis'] = df.diagnosis.map({'M': 0, \n",
        "                                  'B': 1})"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SPA29vFtH2V"
      },
      "source": [
        "X = df.drop(columns=['diagnosis'])\n",
        "y = df['diagnosis']"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8WYgQY0uQ2C"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bo2BoBgOuEhi",
        "outputId": "b411fc28-73c3-4c55-b65d-7dafac109510"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StandardScaler()"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EC7sHWGjuNUn"
      },
      "source": [
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X65z9g_TuhKS",
        "outputId": "acc08bd9-e3fc-4532-ecb6-ec925851b3bc"
      },
      "source": [
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OU53U4vJumin"
      },
      "source": [
        "predictions = logreg.predict(X_test)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1QqqZgFuoqA",
        "outputId": "dfed1303-9ca7-45a9-f13c-22006ba07542"
      },
      "source": [
        "score = logreg.score(X_test, y_test)\n",
        "print(score)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9790209790209791\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-EonJQMurUv",
        "outputId": "407bbdba-2161-4f45-ad19-86946d711174"
      },
      "source": [
        "y_test.values"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1,\n",
              "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
              "       0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
              "       0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
              "       1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8W8V8_tutjx",
        "outputId": "56ce502a-56f7-4e58-ed51-d54892f55677"
      },
      "source": [
        "predictions"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1,\n",
              "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
              "       0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
              "       0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
              "       1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzpP_E9ou8zK"
      },
      "source": [
        "cm = metrics.confusion_matrix(y_test.values, predictions)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rNuQccJviIH",
        "outputId": "ad827479-f3a9-4015-9121-2592065a9538"
      },
      "source": [
        "cm"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[53,  1],\n",
              "       [ 2, 87]])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufgTqPOwvnk_",
        "outputId": "d00b5dc8-cc7a-4827-dba6-a106fb4ef520"
      },
      "source": [
        "cm.shape"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cA4AEjM0vpJf",
        "outputId": "bfef29a1-6e7e-4430-c561-6e79ed4156bb"
      },
      "source": [
        "cm.ravel()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([53,  1,  2, 87])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rN8WUIdovris",
        "outputId": "92d33cc6-9ea7-456d-ee7c-b8a92a613ec7"
      },
      "source": [
        "cm.ravel().shape"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4,)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWybOTZsvtwi"
      },
      "source": [
        "tn, fp, fn, tp = cm.ravel()"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_97EesMIvvv2",
        "outputId": "52094991-95a8-46db-b4a7-c80d44e43d43"
      },
      "source": [
        "tn"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "53"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyXrf6dPvw_x",
        "outputId": "023f9cae-453e-4bc1-b16a-f4ee8a0b63dc"
      },
      "source": [
        "# 3) How many false positives were there?\n",
        "fp"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8szskjFOvx5F",
        "outputId": "df1de446-7834-4bc3-9223-1bddc96b78a1"
      },
      "source": [
        "# 4) How many false negatives were there?\n",
        "fn"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUQjjB6DvyZA",
        "outputId": "6d25102c-78be-491d-bae4-e66ad803b3a4"
      },
      "source": [
        "tp"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "87"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znWtxinTvy8m"
      },
      "source": [
        "import seaborn as sns"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5OOfPJjxnHB"
      },
      "source": [
        "corr = df.corr()"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "WWCRjg0ox7vz",
        "outputId": "7bc32259-5f82-4c1c-b9ff-c11b45895304"
      },
      "source": [
        "plot_confusion_matrix(logreg, X_test, y_test, cmap = 'Greens');"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rDRqrT-yCvB"
      },
      "source": [
        "# 5) For the breast cancer data set, which do you think is more problematic: false positives or false negatives? Explain.  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VTgPboU0Wng"
      },
      "source": [
        "Comparatively false negatives is more problematic than false positives. Because it contains 2 in fn. False positives contains only 1."
      ]
    }
  ]
}